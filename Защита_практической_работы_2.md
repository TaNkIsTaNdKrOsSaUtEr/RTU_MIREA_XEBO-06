Я использовал один из рекомендованных датасетов с kagle(приложу его в гитхаб), вы можете использовать любой другой, но будьте готовы редактировать код. Ссылка на датасет: https://www.kaggle.com/datasets/walekhwatlphilip/intro-to-data-cleaning-eda-and-machine-learning/data

## Решение задания по курсу "Системы ИИ и большие данные"

### 1. Загрузка и предварительная обработка данных

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB

# Загрузка данных
df = pd.read_csv('bi.csv', encoding='ISO-8859-1')

# Информация о данных
print("=== ИНФОРМАЦИЯ О ДАННЫХ ===")
print(df.info())
print("\n=== СТАТИСТИКА ===")
print(df.describe())
print("\n=== ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ ===")
print(df.isnull().sum())
```

### 2. Предобработка данных

```python
# Заполнение пропусков в числовых столбцах
df['Python'] = df['Python'].fillna(df['Python'].mean())
df['DB'] = df['DB'].fillna(df['DB'].mean())

# Нормализация названий стран и образования
df['country'] = df['country'].str.title()
df['prevEducation'] = df['prevEducation'].str.title()

# Унификация гендера
df['gender'] = df['gender'].map({'M': 'Male', 'F': 'Female', 'male': 'Male', 'female': 'Female'})
df['gender'] = df['gender'].fillna('Unknown')

# Создание целевой переменной (успеваемость по Python)
df['Python_Level'] = pd.cut(df['Python'], bins=[0, 60, 80, 100], 
                           labels=['Low', 'Medium', 'High'])

# Кодирование категориальных переменных
label_encoders = {}
categorical_cols = ['gender', 'country', 'residence', 'prevEducation', 'Python_Level']

for col in categorical_cols:
    le = LabelEncoder()
    df[col + '_encoded'] = le.fit_transform(df[col].astype(str))
    label_encoders[col] = le

# Признаки для моделирования
features = ['Age', 'entryEXAM', 'studyHOURS', 'DB', 
           'gender_encoded', 'country_encoded', 'residence_encoded', 'prevEducation_encoded']

X = df[features]
y = df['Python_Level_encoded']

# Разделение на train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Масштабирование признаков
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### 3. Визуализация данных

```python
# Графики для анализа данных
plt.figure(figsize=(15, 10))

# Распределение оценок
plt.subplot(2, 2, 1)
sns.histplot(df['Python'], bins=20, kde=True)
plt.title('Распределение оценок по Python')

# Корреляционная матрица
plt.subplot(2, 2, 2)
numeric_df = df[['Age', 'entryEXAM', 'studyHOURS', 'Python', 'DB']]
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title('Корреляционная матрица')

# Боксплот по странам
plt.subplot(2, 2, 3)
sns.boxplot(x='country', y='Python', data=df[df['country'].isin(df['country'].value_counts().index[:5])])
plt.xticks(rotation=45)
plt.title('Оценки по Python по странам')

# Зависимость от часов обучения
plt.subplot(2, 2, 4)
sns.scatterplot(x='studyHOURS', y='Python', data=df)
plt.title('Зависимость оценки от часов обучения')

plt.tight_layout()
plt.show()
```

### 4. Обучение моделей с подбором гиперпараметров

```python
# Словарь для хранения результатов
results = {}

# a) Дерево решений
print("=== ДЕРЕВО РЕШЕНИЙ ===")
dt_params = {'max_depth': [3, 5, 7, 10], 'min_samples_split': [2, 5, 10]}
dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, scoring='accuracy')
dt_grid.fit(X_train, y_train)
dt_best = dt_grid.best_estimator_
y_pred_dt = dt_best.predict(X_test)
results['Decision Tree'] = accuracy_score(y_test, y_pred_dt)
print(f"Лучшие параметры: {dt_grid.best_params_}")
print(f"Точность: {results['Decision Tree']:.3f}")

# b) Метод опорных векторов
print("\n=== SVM ===")
svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
svm_grid = GridSearchCV(SVC(), svm_params, cv=5, scoring='accuracy')
svm_grid.fit(X_train_scaled, y_train)
svm_best = svm_grid.best_estimator_
y_pred_svm = svm_best.predict(X_test_scaled)
results['SVM'] = accuracy_score(y_test, y_pred_svm)
print(f"Лучшие параметры: {svm_grid.best_params_}")
print(f"Точность: {results['SVM']:.3f}")

# c) K-ближайших соседей
print("\n=== K-NN ===")
knn_params = {'n_neighbors': [3, 5, 7, 10], 'weights': ['uniform', 'distance']}
knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy')
knn_grid.fit(X_train_scaled, y_train)
knn_best = knn_grid.best_estimator_
y_pred_knn = knn_best.predict(X_test_scaled)
results['K-NN'] = accuracy_score(y_test, y_pred_knn)
print(f"Лучшие параметры: {knn_grid.best_params_}")
print(f"Точность: {results['K-NN']:.3f}")

# d) Случайный лес
print("\n=== СЛУЧАЙНЫЙ ЛЕС ===")
rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, None]}
rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='accuracy')
rf_grid.fit(X_train, y_train)
rf_best = rf_grid.best_estimator_
y_pred_rf = rf_best.predict(X_test)
results['Random Forest'] = accuracy_score(y_test, y_pred_rf)
print(f"Лучшие параметры: {rf_grid.best_params_}")
print(f"Точность: {results['Random Forest']:.3f}")

# e) Логистическая регрессия
print("\n=== ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ ===")
lr_params = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}
lr_grid = GridSearchCV(LogisticRegression(), lr_params, cv=5, scoring='accuracy')
lr_grid.fit(X_train_scaled, y_train)
lr_best = lr_grid.best_estimator_
y_pred_lr = lr_best.predict(X_test_scaled)
results['Logistic Regression'] = accuracy_score(y_test, y_pred_lr)
print(f"Лучшие параметры: {lr_grid.best_params_}")
print(f"Точность: {results['Logistic Regression']:.3f}")

# f) Наивный Байес
print("\n=== НАИВНЫЙ БАЙЕС ===")
nb = GaussianNB()
nb.fit(X_train_scaled, y_train)
y_pred_nb = nb.predict(X_test_scaled)
results['Naive Bayes'] = accuracy_score(y_test, y_pred_nb)
print(f"Точность: {results['Naive Bayes']:.3f}")
```

### 5. Сравнение моделей и визуализация результатов

```python
# Сравнение точности моделей
plt.figure(figsize=(12, 6))

# График точности
plt.subplot(1, 2, 1)
models = list(results.keys())
accuracies = list(results.values())
bars = plt.bar(models, accuracies, color=['skyblue', 'lightcoral', 'lightgreen', 
                                         'gold', 'lightpink', 'lightsteelblue'])
plt.title('Сравнение точности моделей')
plt.xticks(rotation=45)
plt.ylabel('Accuracy')

# Добавление значений на столбцы
for bar, accuracy in zip(bars, accuracies):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{accuracy:.3f}', ha='center', va='bottom')

# Матрица ошибок для лучшей модели
best_model_name = max(results, key=results.get)
if best_model_name in ['SVM', 'K-NN', 'Logistic Regression', 'Naive Bayes']:
    best_predictions = eval(f'y_pred_{best_model_name.lower().replace(" ", "_").replace("-", "")}')
else:
    best_predictions = eval(f'y_pred_{best_model_name.lower().replace(" ", "_")}')

plt.subplot(1, 2, 2)
cm = confusion_matrix(y_test, best_predictions)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=label_encoders['Python_Level'].classes_, 
            yticklabels=label_encoders['Python_Level'].classes_)
plt.title(f'Матрица ошибок ({best_model_name})')
plt.ylabel('Истинные значения')
plt.xlabel('Предсказанные значения')

plt.tight_layout()
plt.show()

# Детальный отчет по лучшей модели
print(f"\n=== ДЕТАЛЬНЫЙ ОТЧЕТ ДЛЯ {best_model_name} ===")
print(classification_report(y_test, best_predictions, 
                          target_names=label_encoders['Python_Level'].classes_))

# Сводная таблица результатов
results_df = pd.DataFrame({
    'Модель': models,
    'Точность': accuracies
}).sort_values('Точность', ascending=False)

print("\n=== СВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ ===")
print(results_df)
```

### 6. Ключевые выводы

```python
print("=== КЛЮЧЕВЫЕ ВЫВОДЫ ===")
print(f"1. Лучшая модель: {best_model_name} с точностью {results[best_model_name]:.3f}")
print(f"2. Общее количество наблюдений: {len(df)}")
print(f"3. Количество признаков: {len(features)}")
print(f"4. Распределение целевой переменной:")
print(df['Python_Level'].value_counts())
print(f"5. Наиболее важные признаки (из случайного леса):")

# Важность признаков из случайного леса
feature_importance = pd.DataFrame({
    'Признак': features,
    'Важность': rf_best.feature_importances_
}).sort_values('Важность', ascending=False)

print(feature_importance.head())
```

Это полное решение задания, включающее все требуемые этапы: предобработку данных, визуализацию, обучение шести алгоритмов с подбором гиперпараметров и сравнение результатов.

